{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' \"You are a helpful assistant.\"',\n",
       " '\"Farewell, my master, always in every chance first in my mind, as you deserve to be.\"',\n",
       " '\"My master, see I am not asleep, and I compel myself to sleep, that you may not be angry with me.\"',\n",
       " '\"Gratia and I will have to fight for it; I doubt I shall not get the better of her.\"',\n",
       " '\"Whenas, by God\\'s mercy you shall stand upright, my spirit too will stand firm.\"',\n",
       " '\"To grow together like fellow branches in matter of good correspondence and affection; but not in matter of opinions.\"',\n",
       " '\"It is not possible that any nature should be inferior unto art, since that all arts imitate nature.\"',\n",
       " '\"Justice cannot be preserved, if either we settle our minds and affections upon worldly things; or be apt to be deceived, or rash, and inconstant.\"']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import yaml\n",
    "from llama_index.llms import Replicate\n",
    "\n",
    "with open('config/config.yml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "os.environ[\"REPLICATE_API_TOKEN\"] = config['API_KEY']\n",
    "\n",
    "llm = Replicate(\n",
    "    model=config['replicate_config']['model'],\n",
    "    temperature=config['replicate_config']['temperature'],\n",
    "    additional_kwargs=config['replicate_config']['additional_kwargs']\n",
    ")\n",
    "\n",
    "# set tokenizer to match LLM\n",
    "from llama_index import set_global_tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "set_global_tokenizer(\n",
    "    AutoTokenizer.from_pretrained(config['tokenizer']).encode\n",
    ")\n",
    "\n",
    "from llama_index.embeddings import HuggingFaceEmbedding\n",
    "from llama_index import ServiceContext\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=config['embed_model'])\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=llm, embed_model=embed_model\n",
    ")\n",
    "\n",
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, service_context=service_context\n",
    ")\n",
    "\n",
    "query = \"Share one amazing motivational quote. End it with a newline character. Don't generate any introductory line.\"\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(query)\n",
    "res_text = response.response.split('\\n')\n",
    "res_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' \"Farewell, my master, always in every chance first in my mind, as you deserve to be. My master, see I am not asleep, and I compel myself to sleep, that you may not be angry with me.\" - Marcus Aurelius']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Share one amazing motivational quote. End it with a newline character. Don't generate any introductory line.\"\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(query)\n",
    "res_text = response.response.split('\\n')\n",
    "res_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiktokgen_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
